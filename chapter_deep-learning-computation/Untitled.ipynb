{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f213da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1621,  0.3344, -0.0975,  0.1109,  0.1315, -0.4677,  0.2131, -0.0483,\n",
       "          0.2338, -0.2709],\n",
       "        [-0.1159,  0.4168, -0.2490,  0.1038,  0.1473, -0.4194,  0.0854, -0.0716,\n",
       "          0.1894, -0.2436]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.1\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3138e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # 用模型参数声明层。这里，我们声明两个全连接的层\n",
    "    def __init__(self):\n",
    "        # 调用MLP的父类Module的构造函数来执行必要的初始化。\n",
    "        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # 隐藏层\n",
    "        self.out = nn.Linear(256, 10)  # 输出层\n",
    "\n",
    "    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出\n",
    "    def forward(self, X):\n",
    "        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0faaa150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0099,  0.1454,  0.2838, -0.3136,  0.0943, -0.1703, -0.0059,  0.1608,\n",
       "          0.0474, -0.3629],\n",
       "        [-0.0375,  0.1417,  0.1619, -0.2816,  0.0546, -0.0868,  0.0751,  0.0728,\n",
       "          0.2317, -0.3503]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd08491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n",
    "            # 变量_modules中。module的类型是OrderedDict\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ffe8b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1283, -0.2505,  0.0692, -0.0353,  0.0963, -0.1223, -0.0376, -0.2937,\n",
       "          0.1487,  0.2415],\n",
       "        [-0.1198, -0.2287,  0.0902, -0.1079,  0.1324, -0.0883, -0.0382, -0.2606,\n",
       "          0.1839,  0.2386]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2985842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 不计算梯度的随机权重参数。因此其在训练期间保持不变\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        # 使用创建的常量参数以及relu和mm函数\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        # 复用全连接层。这相当于两个全连接层共享参数\n",
    "        X = self.linear(X)\n",
    "        # 控制流\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4b2421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0785, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c39cd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0739, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
    "                                 nn.Linear(64, 32), nn.ReLU())\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "523fb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7f1dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3335],\n",
       "        [-0.4271]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db297c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.1782, -0.2035, -0.2761, -0.2026, -0.1256, -0.0182,  0.1783,  0.2404]])), ('bias', tensor([-0.2701]))])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032c1a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.2701], requires_grad=True)\n",
      "tensor([-0.2701])\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867ce3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.grad == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18e4c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30df4c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(*[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5665acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2701])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baaf6a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4647],\n",
       "        [-0.4647]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                         nn.Linear(8, 4), nn.ReLU())\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        # 在这里嵌套\n",
    "        net.add_module(f'block {i}', block1())\n",
    "    return net\n",
    "\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "rgnet(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a0f76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1a97a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1368, -0.4360,  0.2891,  0.1783, -0.4031,  0.1444, -0.0729,  0.1658])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbe2e9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.3309, -0.2018, -0.4697, -0.4279],\n",
       "                      [-0.3322, -0.1260,  0.4053,  0.3037],\n",
       "                      [-0.0870,  0.1222, -0.1533,  0.4208],\n",
       "                      [ 0.2295,  0.2351,  0.3565, -0.3006],\n",
       "                      [ 0.1078,  0.0512,  0.3338, -0.4425],\n",
       "                      [ 0.0898, -0.0208, -0.1370,  0.3823],\n",
       "                      [ 0.3682, -0.1217, -0.3703,  0.0986],\n",
       "                      [ 0.1293,  0.0053,  0.0513, -0.3592]])),\n",
       "             ('bias',\n",
       "              tensor([-0.1368, -0.4360,  0.2891,  0.1783, -0.4031,  0.1444, -0.0729,  0.1658]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04769f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0142, 0.0073, 0.0066, 0.0026]), tensor(0.))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4333e1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa0b96b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3932, 0.1772, 0.6713, 0.6673])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "def xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)\n",
    "\n",
    "net[0].apply(xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "920c08b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-9.5386, -9.8476,  0.0000,  9.8381],\n",
       "        [-0.0000,  0.0000,  7.8190,  5.3683]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape)\n",
    "                        for name, param in m.named_parameters()][0])\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >= 5\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b65d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ceaa96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a*= a>10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8249e09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a41bf5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.5386, -9.8476,  0.0000,  9.8381],\n",
       "        [-0.0000,  0.0000,  7.8190,  5.3683],\n",
       "        [ 6.7490,  0.0000,  0.0000, -0.0000],\n",
       "        [ 5.0517, -9.7502,  6.4220, -0.0000],\n",
       "        [ 9.5229, -9.5778, -5.8290,  0.0000],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [ 5.9020, -0.0000, -0.0000, -5.0403],\n",
       "        [-5.1756,  0.0000,  0.0000,  0.0000]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12cc407f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-9.5386, -9.8476,  0.0000,  9.8381],\n",
       "                      [-0.0000,  0.0000,  7.8190,  5.3683],\n",
       "                      [ 6.7490,  0.0000,  0.0000, -0.0000],\n",
       "                      [ 5.0517, -9.7502,  6.4220, -0.0000],\n",
       "                      [ 9.5229, -9.5778, -5.8290,  0.0000],\n",
       "                      [ 0.0000, -0.0000,  0.0000, -0.0000],\n",
       "                      [ 5.9020, -0.0000, -0.0000, -5.0403],\n",
       "                      [-5.1756,  0.0000,  0.0000,  0.0000]])),\n",
       "             ('0.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('2.weight',\n",
       "              tensor([[-9.6828, -0.0000, -5.2050, -0.0000,  5.3223,  9.2863, -0.0000, -7.0476]])),\n",
       "             ('2.bias', tensor([0.]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39ef8f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.0000, -8.8476,  1.0000, 10.8381])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "367137c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# 我们需要给共享层一个名称，以便可以引用它的参数\n",
    "shared = nn.Linear(8, 8)\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    nn.Linear(8, 1))\n",
    "net(X)\n",
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2410a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fcc5bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): LazyLinear(in_features=0, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "net = nn.Sequential(nn.LazyLinear(256), nn.ReLU(),nn.Linear(256,10))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2d49005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('weight', <UninitializedParameter>),\n",
       "              ('bias', <UninitializedParameter>)]),\n",
       " OrderedDict(),\n",
       " OrderedDict([('weight',\n",
       "               tensor([[ 0.0365,  0.0068,  0.0474,  ..., -0.0210, -0.0513, -0.0355],\n",
       "                       [-0.0327, -0.0108, -0.0062,  ...,  0.0219,  0.0338,  0.0065],\n",
       "                       [-0.0555, -0.0278,  0.0356,  ..., -0.0206, -0.0286,  0.0212],\n",
       "                       ...,\n",
       "                       [-0.0274,  0.0104, -0.0229,  ...,  0.0019,  0.0374, -0.0188],\n",
       "                       [-0.0305,  0.0140, -0.0048,  ..., -0.0503, -0.0611,  0.0053],\n",
       "                       [-0.0247, -0.0619, -0.0017,  ...,  0.0428,  0.0460,  0.0021]])),\n",
       "              ('bias',\n",
       "               tensor([-0.0258, -0.0467, -0.0117,  0.0112, -0.0435,  0.0133, -0.0120,  0.0402,\n",
       "                        0.0445,  0.0461]))])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[net[i].state_dict() for i in range(len(net))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6885a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "low = torch.finfo(torch.float32).min/10\n",
    "high = torch.finfo(torch.float32).max/10\n",
    "X = torch.zeros([2,20],dtype=torch.float32).uniform_(low, high)\n",
    "net(X)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc744e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.4028234663852886e+37"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d940d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4028234663852886e+37"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4192e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4bd02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd612f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5301b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5ef806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.7521e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424d299a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.2394e-02, -2.4934e-01,  7.1600e-01, -1.0812e-01, -6.4436e-01,\n",
       "          2.6018e-01, -1.4831e-01,  1.9070e-01, -1.3747e-01, -1.8836e-01,\n",
       "          2.8194e-01,  2.8141e-01, -2.6830e-01,  5.1927e-01, -5.3656e-02,\n",
       "          5.9355e-01,  7.6426e-01, -4.4146e-02, -3.7050e-01,  4.1499e-02,\n",
       "          7.3881e-02, -2.3610e-01, -3.9936e-01,  1.1862e-01,  3.3051e-01,\n",
       "          2.0875e-01, -4.3963e-01, -3.2148e-01, -1.8901e-01,  6.1409e-01,\n",
       "          5.2177e-01, -1.5571e-01,  2.9292e-01, -6.2267e-01,  3.5871e-01,\n",
       "          3.9282e-01,  1.5132e-01,  5.8188e-01, -3.0214e-01,  1.1776e-01,\n",
       "         -4.7709e-01,  1.4330e-01, -8.2027e-02,  1.3908e-02,  5.0274e-01,\n",
       "         -4.2411e-01, -5.0365e-01,  3.4765e-01, -9.7007e-01, -8.0717e-01,\n",
       "         -4.7896e-01,  2.5106e-01, -8.3362e-02,  2.4920e-01,  1.3610e-01,\n",
       "          5.8115e-01, -1.0364e-01, -1.9656e-01,  1.9953e-01,  4.1960e-01,\n",
       "          4.3628e-01,  1.5992e-01, -1.8830e-01,  5.1590e-01,  3.4708e-01,\n",
       "         -1.4832e-01, -5.2510e-03, -2.0038e-01, -2.0568e-01, -2.2613e-01,\n",
       "         -1.9916e-01, -3.3194e-01,  7.3717e-01,  2.4983e-01, -2.2422e-01,\n",
       "          8.0059e-02,  7.0204e-01, -8.3253e-01,  8.3055e-01,  1.2492e-01,\n",
       "         -2.9710e-01, -3.3498e-01,  5.4146e-02,  4.0265e-01,  9.1455e-03,\n",
       "          3.0441e-01,  5.8241e-02, -5.5686e-01, -1.9486e-01, -3.8638e-02,\n",
       "         -9.6020e-02,  3.1677e-01,  5.3016e-01, -4.0367e-01, -1.7667e-01,\n",
       "         -6.8466e-02, -1.3585e-01,  1.5832e-01,  2.2768e-01, -4.7538e-01,\n",
       "         -8.7969e-02,  8.2046e-02,  1.8280e-01, -7.0152e-01, -1.8857e-01,\n",
       "         -3.2092e-01, -1.7963e-01,  2.3577e-01, -3.2415e-01, -4.4773e-01,\n",
       "          4.2170e-01,  1.4807e-01,  3.0686e-01,  1.6828e-01, -5.7815e-01,\n",
       "          1.5780e-01,  6.1282e-01, -2.3876e-01, -3.1847e-01, -3.0193e-01,\n",
       "          1.8561e-02,  1.8787e-01, -6.6800e-02, -4.9638e-01, -1.3108e-01,\n",
       "         -3.4880e-01,  3.6741e-01,  3.1847e-02],\n",
       "        [ 3.2832e-01, -5.2426e-01,  4.7178e-01, -6.2083e-02, -8.2931e-01,\n",
       "          6.8233e-01,  9.4741e-02, -5.3606e-01, -2.2790e-01, -3.3804e-01,\n",
       "          5.9569e-01, -1.3957e-01,  2.5478e-01, -1.5759e-01, -2.6466e-01,\n",
       "          2.6033e-01,  1.7396e-01, -4.9961e-01, -4.1958e-01, -1.3246e-01,\n",
       "          5.6089e-01,  1.6290e-01, -2.2527e-01, -2.1635e-01,  2.4053e-01,\n",
       "         -7.2253e-02, -5.3698e-01, -7.0100e-03, -9.6547e-02,  4.3843e-01,\n",
       "          5.5734e-01, -3.7260e-01,  1.5208e-01, -3.4993e-01,  1.1988e-01,\n",
       "          2.7293e-01, -3.0180e-01,  3.4693e-01, -3.5303e-01,  3.6376e-01,\n",
       "         -1.2311e-01,  2.7747e-01,  4.2106e-02,  1.9278e-01,  2.2056e-01,\n",
       "         -2.9857e-01, -4.2847e-01,  6.1293e-01, -8.1953e-01, -4.8107e-01,\n",
       "         -3.8510e-01, -2.7852e-01, -1.0745e-02, -2.2583e-01,  7.7466e-01,\n",
       "          7.9702e-01, -4.6594e-02, -1.0822e-01,  2.4902e-01, -9.7977e-02,\n",
       "          3.0396e-01,  9.7153e-02, -4.0768e-01,  2.3960e-04,  2.6134e-01,\n",
       "         -3.0669e-01, -4.5517e-01, -3.2174e-02,  1.8062e-01, -2.6718e-01,\n",
       "          2.6995e-01, -9.6572e-01,  7.8471e-01,  3.7024e-01, -6.4997e-01,\n",
       "          1.8680e-01,  2.1014e-01, -1.3048e+00,  1.1307e+00, -1.0659e-01,\n",
       "         -9.5245e-02,  1.9323e-01, -1.6675e-01,  9.1406e-01, -1.8643e-01,\n",
       "         -1.4012e-01,  1.5330e-03, -4.7799e-01, -3.9410e-02, -5.2735e-01,\n",
       "         -1.9087e-01, -9.7050e-02,  4.8765e-01, -6.4522e-01, -8.8093e-01,\n",
       "         -6.7291e-02, -1.1517e-01, -2.5138e-01,  4.4528e-01, -6.0631e-01,\n",
       "          6.3279e-02,  7.3498e-01,  2.1984e-01, -5.9600e-01, -7.6190e-01,\n",
       "         -2.8721e-01,  1.5477e-01,  8.4127e-01, -8.0013e-01, -5.8053e-01,\n",
       "          6.6434e-01,  4.4453e-01,  9.5974e-01,  5.4714e-01, -4.5735e-01,\n",
       "          1.3453e-01,  4.7353e-01, -3.2956e-01,  2.9039e-01, -1.0957e-01,\n",
       "         -2.8385e-01,  9.5753e-02, -1.8732e-01, -3.9657e-01,  5.1916e-02,\n",
       "          3.6629e-03,  1.8568e-01,  2.3868e-01],\n",
       "        [ 3.3179e-01, -1.3462e-01,  5.6631e-01, -2.7187e-03, -6.8839e-01,\n",
       "          1.9466e-01, -1.2096e-02, -9.5849e-02, -3.8153e-01, -1.4644e-01,\n",
       "          4.9106e-01,  2.8100e-01, -1.1418e-01,  2.1272e-01, -3.5168e-01,\n",
       "          4.5829e-01,  5.1696e-01, -1.0655e-01, -2.9086e-01, -2.8024e-01,\n",
       "          1.0346e-01,  8.0698e-02, -1.6848e-01,  2.0114e-02,  5.3524e-01,\n",
       "         -3.1204e-01, -4.6446e-01, -1.0300e-01, -1.1494e-01,  4.7131e-01,\n",
       "          3.9514e-01, -2.0875e-01,  1.3497e-01, -2.0202e-01,  4.9367e-01,\n",
       "          4.3839e-01, -1.5283e-02,  3.1467e-01, -4.8234e-01, -3.3844e-02,\n",
       "         -5.5119e-01,  3.8723e-01,  3.2805e-02,  2.9431e-01,  2.3888e-01,\n",
       "         -1.4230e-01, -4.2973e-01,  4.4504e-01, -5.3689e-01, -5.8315e-01,\n",
       "         -4.4822e-01, -2.3512e-01, -5.1618e-02,  3.2947e-01,  4.2571e-01,\n",
       "          3.4948e-01,  1.5672e-01, -3.7379e-01,  2.7498e-01,  4.0697e-01,\n",
       "          1.0995e-02,  2.1661e-01, -7.6953e-01,  5.5979e-01,  2.5863e-01,\n",
       "         -3.5237e-01, -3.7065e-01, -1.2571e-01, -1.7585e-01, -1.8539e-01,\n",
       "          1.5738e-01, -4.2681e-01,  5.5519e-01, -1.0580e-01, -2.2143e-01,\n",
       "         -5.2116e-01,  3.8929e-01, -6.0348e-01,  6.3435e-01, -9.6485e-02,\n",
       "         -3.1093e-01,  7.3583e-02, -1.0207e-01,  6.6397e-01,  6.5689e-02,\n",
       "          4.2437e-01,  5.0235e-01, -1.8238e-01, -2.7390e-01, -2.3376e-01,\n",
       "          5.7756e-02,  2.1953e-01,  2.5939e-01, -7.5428e-02, -4.2150e-01,\n",
       "          1.8081e-02,  1.6593e-01,  2.3443e-02, -8.0049e-02, -4.6516e-01,\n",
       "          3.5953e-02,  3.2102e-01,  5.1810e-01, -6.1454e-01, -4.2135e-01,\n",
       "         -1.4338e-01,  2.3109e-01,  4.2236e-01, -2.8875e-01, -1.7884e-01,\n",
       "          4.7223e-01,  2.8110e-01,  5.5103e-01,  3.4286e-02, -5.1025e-02,\n",
       "         -5.5419e-02,  6.0629e-01,  7.5575e-02,  2.0815e-01, -5.5948e-01,\n",
       "         -8.5464e-02,  7.9735e-03, -1.0898e-01, -4.5601e-02,  5.3304e-02,\n",
       "         -1.5265e-01,  3.1281e-01,  1.4772e-01],\n",
       "        [ 2.8940e-01, -3.2501e-01,  6.5738e-01,  5.9794e-04, -7.3981e-01,\n",
       "          4.2815e-01, -2.6197e-03, -3.9659e-01, -3.4272e-01, -3.3039e-01,\n",
       "          5.1148e-01,  9.6705e-02,  1.3389e-01,  7.1095e-02, -2.4632e-01,\n",
       "          3.6836e-01,  3.3274e-01, -3.4237e-01, -4.2063e-01, -2.0794e-01,\n",
       "          3.4026e-01,  6.4117e-02, -2.7373e-01, -2.2825e-01,  4.0584e-01,\n",
       "         -6.4440e-02, -4.7300e-01, -1.7614e-01, -3.5810e-02,  5.0060e-01,\n",
       "          5.3605e-01, -3.3044e-01,  7.3680e-02, -4.0450e-01,  2.3061e-01,\n",
       "          4.0996e-01, -2.5864e-01,  4.1433e-01, -3.4222e-01,  2.1785e-01,\n",
       "         -2.9911e-01,  3.7664e-01, -2.1513e-02,  1.1041e-01,  1.8582e-01,\n",
       "         -1.6386e-01, -4.4683e-01,  5.3033e-01, -7.9096e-01, -5.3929e-01,\n",
       "         -4.4821e-01, -1.8083e-01, -6.0574e-02,  1.2703e-01,  6.1451e-01,\n",
       "          7.0046e-01,  6.4847e-02, -1.6885e-01,  2.9557e-01,  1.1807e-01,\n",
       "          2.3322e-01,  1.2453e-01, -5.1376e-01,  1.9994e-01,  2.9986e-01,\n",
       "         -2.7344e-01, -3.9708e-01,  1.0290e-01, -3.4312e-02, -2.2428e-01,\n",
       "          1.1171e-01, -7.5524e-01,  7.7221e-01,  2.5774e-01, -4.0907e-01,\n",
       "         -1.3483e-01,  2.7414e-01, -9.4760e-01,  8.2563e-01, -5.7511e-02,\n",
       "         -1.3137e-01,  1.6194e-01, -1.5934e-01,  8.2118e-01, -7.7648e-02,\n",
       "          6.5497e-02,  2.3665e-01, -4.2830e-01, -6.2725e-02, -4.1886e-01,\n",
       "         -1.4176e-01,  7.6232e-02,  5.2451e-01, -3.9505e-01, -6.7418e-01,\n",
       "         -6.5095e-02,  8.3069e-03, -1.8711e-01,  2.0907e-01, -4.9861e-01,\n",
       "          6.4261e-02,  4.4963e-01,  4.0563e-01, -6.0899e-01, -6.2406e-01,\n",
       "         -8.7713e-02,  2.4827e-01,  7.1941e-01, -5.0427e-01, -4.5953e-01,\n",
       "          5.1746e-01,  3.1676e-01,  8.4247e-01,  4.2108e-01, -3.3111e-01,\n",
       "          6.3415e-02,  4.2961e-01, -2.1885e-01,  2.2947e-01, -2.9844e-01,\n",
       "         -1.1302e-01,  7.7150e-02, -4.2770e-02, -2.5371e-01, -6.5319e-02,\n",
       "         -3.6882e-02,  2.5331e-01,  2.0893e-01]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab5183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2f031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
