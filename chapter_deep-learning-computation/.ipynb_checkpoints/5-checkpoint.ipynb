{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f213da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1621,  0.3344, -0.0975,  0.1109,  0.1315, -0.4677,  0.2131, -0.0483,\n",
       "          0.2338, -0.2709],\n",
       "        [-0.1159,  0.4168, -0.2490,  0.1038,  0.1473, -0.4194,  0.0854, -0.0716,\n",
       "          0.1894, -0.2436]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.1\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3138e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # 用模型参数声明层。这里，我们声明两个全连接的层\n",
    "    def __init__(self):\n",
    "        # 调用MLP的父类Module的构造函数来执行必要的初始化。\n",
    "        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # 隐藏层\n",
    "        self.out = nn.Linear(256, 10)  # 输出层\n",
    "\n",
    "    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出\n",
    "    def forward(self, X):\n",
    "        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0faaa150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0099,  0.1454,  0.2838, -0.3136,  0.0943, -0.1703, -0.0059,  0.1608,\n",
       "          0.0474, -0.3629],\n",
       "        [-0.0375,  0.1417,  0.1619, -0.2816,  0.0546, -0.0868,  0.0751,  0.0728,\n",
       "          0.2317, -0.3503]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd08491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n",
    "            # 变量_modules中。module的类型是OrderedDict\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ffe8b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1283, -0.2505,  0.0692, -0.0353,  0.0963, -0.1223, -0.0376, -0.2937,\n",
       "          0.1487,  0.2415],\n",
       "        [-0.1198, -0.2287,  0.0902, -0.1079,  0.1324, -0.0883, -0.0382, -0.2606,\n",
       "          0.1839,  0.2386]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2985842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 不计算梯度的随机权重参数。因此其在训练期间保持不变\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        # 使用创建的常量参数以及relu和mm函数\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        # 复用全连接层。这相当于两个全连接层共享参数\n",
    "        X = self.linear(X)\n",
    "        # 控制流\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4b2421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0785, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c39cd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0739, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
    "                                 nn.Linear(64, 32), nn.ReLU())\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "523fb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7f1dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3335],\n",
       "        [-0.4271]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db297c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.1782, -0.2035, -0.2761, -0.2026, -0.1256, -0.0182,  0.1783,  0.2404]])), ('bias', tensor([-0.2701]))])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032c1a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.2701], requires_grad=True)\n",
      "tensor([-0.2701])\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867ce3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.grad == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18e4c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30df4c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(*[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5665acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2701])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baaf6a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4647],\n",
       "        [-0.4647]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                         nn.Linear(8, 4), nn.ReLU())\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        # 在这里嵌套\n",
    "        net.add_module(f'block {i}', block1())\n",
    "    return net\n",
    "\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "rgnet(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a0f76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1a97a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1368, -0.4360,  0.2891,  0.1783, -0.4031,  0.1444, -0.0729,  0.1658])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbe2e9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.3309, -0.2018, -0.4697, -0.4279],\n",
       "                      [-0.3322, -0.1260,  0.4053,  0.3037],\n",
       "                      [-0.0870,  0.1222, -0.1533,  0.4208],\n",
       "                      [ 0.2295,  0.2351,  0.3565, -0.3006],\n",
       "                      [ 0.1078,  0.0512,  0.3338, -0.4425],\n",
       "                      [ 0.0898, -0.0208, -0.1370,  0.3823],\n",
       "                      [ 0.3682, -0.1217, -0.3703,  0.0986],\n",
       "                      [ 0.1293,  0.0053,  0.0513, -0.3592]])),\n",
       "             ('bias',\n",
       "              tensor([-0.1368, -0.4360,  0.2891,  0.1783, -0.4031,  0.1444, -0.0729,  0.1658]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04769f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0142, 0.0073, 0.0066, 0.0026]), tensor(0.))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4333e1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa0b96b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3932, 0.1772, 0.6713, 0.6673])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "def xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)\n",
    "\n",
    "net[0].apply(xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "920c08b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-9.5386, -9.8476,  0.0000,  9.8381],\n",
       "        [-0.0000,  0.0000,  7.8190,  5.3683]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape)\n",
    "                        for name, param in m.named_parameters()][0])\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >= 5\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b65d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ceaa96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a*= a>10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8249e09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a41bf5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.5386, -9.8476,  0.0000,  9.8381],\n",
       "        [-0.0000,  0.0000,  7.8190,  5.3683],\n",
       "        [ 6.7490,  0.0000,  0.0000, -0.0000],\n",
       "        [ 5.0517, -9.7502,  6.4220, -0.0000],\n",
       "        [ 9.5229, -9.5778, -5.8290,  0.0000],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [ 5.9020, -0.0000, -0.0000, -5.0403],\n",
       "        [-5.1756,  0.0000,  0.0000,  0.0000]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12cc407f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-9.5386, -9.8476,  0.0000,  9.8381],\n",
       "                      [-0.0000,  0.0000,  7.8190,  5.3683],\n",
       "                      [ 6.7490,  0.0000,  0.0000, -0.0000],\n",
       "                      [ 5.0517, -9.7502,  6.4220, -0.0000],\n",
       "                      [ 9.5229, -9.5778, -5.8290,  0.0000],\n",
       "                      [ 0.0000, -0.0000,  0.0000, -0.0000],\n",
       "                      [ 5.9020, -0.0000, -0.0000, -5.0403],\n",
       "                      [-5.1756,  0.0000,  0.0000,  0.0000]])),\n",
       "             ('0.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('2.weight',\n",
       "              tensor([[-9.6828, -0.0000, -5.2050, -0.0000,  5.3223,  9.2863, -0.0000, -7.0476]])),\n",
       "             ('2.bias', tensor([0.]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39ef8f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.0000, -8.8476,  1.0000, 10.8381])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "367137c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# 我们需要给共享层一个名称，以便可以引用它的参数\n",
    "shared = nn.Linear(8, 8)\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    nn.Linear(8, 1))\n",
    "net(X)\n",
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2410a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fcc5bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): LazyLinear(in_features=0, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "net = nn.Sequential(nn.LazyLinear(256), nn.ReLU(),nn.Linear(256,10))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d49005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('weight', <UninitializedParameter>),\n",
       "              ('bias', <UninitializedParameter>)]),\n",
       " OrderedDict(),\n",
       " OrderedDict([('weight',\n",
       "               tensor([[-1.7882e-02, -5.9462e-02, -6.3973e-03,  ..., -3.5650e-02,\n",
       "                        -2.1644e-05,  3.3874e-02],\n",
       "                       [ 5.9455e-02, -4.3125e-02, -3.4836e-02,  ..., -7.2742e-03,\n",
       "                        -2.1134e-02,  6.0765e-02],\n",
       "                       [-3.6757e-02,  3.1354e-02, -5.0320e-02,  ..., -2.7340e-02,\n",
       "                         5.8414e-02,  3.4922e-02],\n",
       "                       ...,\n",
       "                       [ 6.0380e-02,  5.2377e-02,  4.5505e-02,  ..., -1.1676e-02,\n",
       "                        -1.4830e-02, -1.9998e-02],\n",
       "                       [-5.4820e-02, -4.2243e-02, -4.0840e-02,  ..., -5.8522e-04,\n",
       "                         4.8966e-02, -5.7866e-02],\n",
       "                       [ 9.1680e-03,  5.3936e-02,  4.3567e-02,  ..., -2.0278e-02,\n",
       "                         2.1227e-02, -2.2285e-02]])),\n",
       "              ('bias',\n",
       "               tensor([-0.0122,  0.0130,  0.0010, -0.0599,  0.0207, -0.0599,  0.0294, -0.0093,\n",
       "                       -0.0516, -0.0214]))])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[net[i].state_dict() for i in range(len(net))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6885a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "low = torch.finfo(torch.float32).min/10\n",
    "high = torch.finfo(torch.float32).max/10\n",
    "X = torch.zeros([2,20],dtype=torch.float32).uniform_(low, high)\n",
    "net(X)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc744e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.4028234663852886e+37"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d940d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4028234663852886e+37"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4192e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4bd02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd612f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5301b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c5ef806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0268e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "424d299a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4269e-02,  1.5388e-01, -2.8648e-01,  3.7712e-01, -3.1574e-01,\n",
       "         -8.8463e-01, -1.7592e-01,  5.5223e-01,  1.9301e-01, -5.5548e-01,\n",
       "         -3.3577e-01, -7.6941e-02,  2.5568e-01, -2.6437e-01, -2.5563e-01,\n",
       "         -2.4424e-01,  1.1911e-01,  3.5435e-01,  6.4722e-02,  4.0116e-01,\n",
       "         -2.8704e-01, -1.2416e-01, -1.1496e-01, -3.9990e-01,  2.2693e-01,\n",
       "          1.5481e-01, -3.8928e-01, -2.0838e-01,  2.9340e-02,  4.4121e-02,\n",
       "          5.4471e-01, -2.5810e-01, -5.9561e-01,  1.9464e-02, -2.1710e-01,\n",
       "         -2.2675e-01,  9.8288e-01,  6.4091e-01,  2.3451e-01,  2.2695e-02,\n",
       "          1.9574e-01, -2.9510e-02, -1.6844e-01,  3.2973e-01, -2.2090e-01,\n",
       "         -2.2187e-01,  3.4128e-01, -6.9265e-01, -2.5459e-01, -1.4466e-01,\n",
       "          8.8989e-02,  1.2924e-01, -2.4259e-02, -2.1263e-01,  2.0965e-02,\n",
       "          1.9710e-01, -3.5008e-01,  3.5457e-01,  1.6156e-02, -3.0908e-01,\n",
       "         -1.4371e-01,  4.0964e-01,  3.0087e-01,  1.2807e-01,  2.2406e-01,\n",
       "         -1.6790e-01,  5.1771e-01,  2.5178e-01, -1.7314e-01,  3.9075e-01,\n",
       "         -3.8070e-01,  6.6738e-03,  5.8798e-02, -2.9002e-01, -1.6480e-01,\n",
       "         -6.0739e-01,  1.6770e-01,  1.1788e-01, -1.1842e-01,  4.8672e-03,\n",
       "          3.0356e-01, -4.3739e-01, -5.3507e-01, -3.8373e-01,  4.3189e-01,\n",
       "          2.3546e-01, -2.4771e-01,  2.9196e-01,  4.3850e-02, -2.4125e-01,\n",
       "          5.6434e-01,  1.9550e-01, -2.0023e-01,  3.3248e-01,  3.9677e-01,\n",
       "          5.5856e-01, -1.6930e-01,  4.1191e-01,  2.3972e-02, -2.1916e-01,\n",
       "         -7.4510e-02,  5.0461e-01, -7.4069e-02, -3.0311e-01, -3.3297e-01,\n",
       "         -2.0966e-01, -5.1153e-02,  1.5081e-01, -2.4013e-01,  9.5600e-02,\n",
       "         -9.1966e-02,  3.1539e-01, -3.0026e-01, -1.6058e-01,  2.4554e-01,\n",
       "          7.3759e-02, -9.7551e-02,  1.4581e-01,  3.4059e-01, -2.4137e-01,\n",
       "         -3.3407e-01,  6.2195e-01, -3.6397e-01, -2.5227e-01,  7.6632e-01,\n",
       "          5.7494e-02,  1.3392e-01, -7.6851e-01],\n",
       "        [ 4.4247e-02,  1.3012e-01, -3.2721e-01,  2.7374e-01, -4.6470e-01,\n",
       "         -3.4922e-01, -2.8905e-01,  2.9164e-01,  1.0363e-01, -2.1187e-01,\n",
       "         -4.0521e-01, -1.1686e-01,  9.9127e-02,  9.2178e-03, -5.2753e-01,\n",
       "         -3.0380e-01,  7.2920e-02,  6.2504e-02,  8.0237e-02,  3.4170e-01,\n",
       "         -3.0281e-01,  2.3113e-01, -1.8194e-01, -1.2861e-01,  4.3024e-02,\n",
       "          1.5414e-01, -5.2002e-01, -7.0709e-02,  4.5794e-02, -2.9589e-01,\n",
       "          5.0402e-01, -3.4623e-01, -2.1636e-01,  4.5235e-02, -2.1185e-01,\n",
       "         -4.9610e-01,  7.3453e-01,  2.1042e-01,  4.0967e-01,  1.7298e-01,\n",
       "          2.8331e-01,  2.0722e-01, -3.1745e-01,  3.4811e-02, -2.6189e-01,\n",
       "         -2.5833e-01,  6.1951e-02, -4.7440e-01, -2.4479e-01, -1.7344e-01,\n",
       "          6.3564e-02, -2.3110e-01, -2.6343e-01, -2.4342e-01,  9.5020e-02,\n",
       "          1.0323e-01, -2.7009e-02,  5.0816e-01,  7.0093e-02, -1.6768e-01,\n",
       "         -5.2214e-01,  5.8539e-01,  4.1412e-01,  8.6319e-02,  3.2675e-02,\n",
       "         -1.6990e-01,  4.5538e-01,  5.8003e-02,  4.2762e-02,  2.8615e-01,\n",
       "         -5.8367e-01,  3.6529e-01,  2.2453e-01, -4.4943e-01, -1.0684e-01,\n",
       "         -3.9006e-01,  2.8705e-01, -3.6124e-03, -3.4531e-01,  1.4993e-02,\n",
       "         -7.8353e-02, -8.0086e-01, -4.0872e-01, -3.3760e-01,  6.4544e-01,\n",
       "          1.8169e-01, -2.3394e-01,  3.9229e-01, -2.7863e-01, -2.0844e-01,\n",
       "          2.0033e-01,  1.7870e-01, -4.4160e-01,  1.8005e-01,  2.8127e-01,\n",
       "          4.2839e-01,  1.5097e-01,  1.7270e-01, -9.3709e-02,  1.8805e-02,\n",
       "         -4.1217e-02,  3.8660e-01,  1.1354e-01, -5.9442e-02,  7.0467e-02,\n",
       "          6.7957e-02,  2.2668e-01, -1.7849e-01, -2.7337e-01,  2.2539e-01,\n",
       "          2.2957e-02,  2.2019e-02, -1.2705e-01, -1.9186e-01,  9.3335e-02,\n",
       "          1.8489e-01, -1.5594e-01,  7.2909e-04,  5.1483e-02, -1.1074e-01,\n",
       "         -1.1721e-01,  5.9369e-01, -1.8869e-01, -3.9535e-01,  6.1504e-01,\n",
       "          1.9752e-01,  1.3826e-01, -7.0105e-01],\n",
       "        [ 1.2507e-01,  5.0518e-02,  3.9576e-02, -2.4047e-02, -6.2720e-01,\n",
       "         -7.0486e-01, -6.6774e-01,  9.7857e-02, -1.9090e-01, -5.6936e-01,\n",
       "         -5.8855e-01,  1.3685e-01,  9.9830e-02,  4.9640e-02, -3.4732e-01,\n",
       "         -4.8189e-02,  2.9726e-02, -4.2037e-01,  5.9084e-01,  2.7947e-01,\n",
       "         -3.0678e-02,  4.4911e-01, -1.5590e-01, -1.6525e-01,  2.2936e-01,\n",
       "          8.4095e-02, -3.2171e-01, -5.3768e-01,  3.0555e-02, -8.7582e-02,\n",
       "          7.5104e-01, -4.0940e-01, -5.1233e-01, -5.0181e-01, -2.8776e-01,\n",
       "         -8.2803e-01,  8.8662e-01,  7.2214e-01,  4.8441e-01,  1.2633e-01,\n",
       "          2.0092e-01,  1.0511e-02, -1.5256e-01,  1.3689e-02, -1.1702e-01,\n",
       "         -1.0408e-01,  3.5265e-01, -8.6724e-02, -1.5756e-01,  2.0405e-01,\n",
       "          8.2505e-02, -1.6420e-01, -5.4586e-02,  9.4227e-02,  6.5561e-01,\n",
       "          1.2507e-01, -5.9121e-01,  2.5793e-01,  3.5558e-01, -7.5454e-02,\n",
       "         -7.0818e-01,  5.5093e-01,  2.6632e-01,  2.4913e-01,  7.2466e-02,\n",
       "         -2.2072e-02,  6.4535e-01, -1.4246e-01,  9.2041e-02,  5.5508e-01,\n",
       "         -6.1735e-01,  5.7527e-01,  1.5211e-01, -9.2859e-02, -7.1418e-02,\n",
       "         -4.0164e-01,  1.5811e-01, -2.0817e-01, -3.6050e-01,  3.5678e-01,\n",
       "          1.2313e-01, -3.9824e-01, -4.1410e-01,  1.1492e-01,  7.6703e-01,\n",
       "          3.7082e-01,  5.5419e-02,  1.8325e-01, -1.7698e-01, -1.0365e-01,\n",
       "          6.2049e-01,  3.6944e-01, -2.4109e-01,  4.1571e-01,  2.6600e-01,\n",
       "         -2.2244e-03,  2.7509e-02,  5.5136e-01,  2.8685e-01,  2.6268e-01,\n",
       "         -5.2860e-02,  2.0605e-01,  5.9129e-02, -1.6846e-01, -2.4526e-01,\n",
       "         -5.2406e-02,  3.5319e-01,  2.8966e-01, -2.6302e-01,  1.1060e-01,\n",
       "         -3.5716e-01,  2.6897e-01, -2.3365e-01,  2.5810e-02,  2.8544e-01,\n",
       "         -3.7000e-01,  2.3387e-02, -1.9391e-01,  2.1264e-01, -2.2816e-01,\n",
       "         -4.3605e-02,  7.5797e-01, -2.4878e-01, -3.9232e-01,  7.9701e-01,\n",
       "         -2.9627e-01,  5.6756e-01, -7.1095e-01],\n",
       "        [ 3.0475e-01, -4.3306e-02, -1.2734e-02,  2.4947e-01, -5.3269e-01,\n",
       "         -4.9470e-01, -4.8404e-01,  4.6690e-01,  1.7861e-01, -4.3375e-01,\n",
       "         -6.2608e-01,  2.3361e-01,  4.9116e-01,  6.1131e-02, -5.3036e-01,\n",
       "         -1.3906e-01,  3.4540e-01, -8.9941e-02,  6.2729e-03,  5.3879e-01,\n",
       "         -1.9171e-01,  2.5327e-01, -3.7852e-01, -9.4766e-02,  1.6559e-01,\n",
       "         -1.4663e-01, -5.0749e-01, -3.8062e-01,  6.5708e-02, -1.4985e-01,\n",
       "          6.8843e-01, -1.5969e-01, -4.3216e-01, -1.7706e-01, -3.9487e-01,\n",
       "         -4.6406e-01,  8.7376e-01,  5.5209e-01,  8.5917e-02, -1.5972e-01,\n",
       "          1.4023e-01,  2.9846e-03, -3.6884e-01,  2.5865e-01, -4.2101e-01,\n",
       "         -7.8596e-02,  2.8319e-01, -3.2031e-01, -5.6240e-01, -2.1249e-01,\n",
       "          2.4269e-01, -1.2198e-01, -1.8784e-01, -2.2453e-01,  2.4298e-01,\n",
       "         -6.3647e-03, -2.2454e-01,  5.5016e-01,  2.4009e-01, -4.8404e-02,\n",
       "         -3.7316e-01,  5.2788e-01,  8.2720e-02, -2.2473e-02,  6.1282e-02,\n",
       "         -2.7350e-01,  4.4514e-01,  2.2020e-01, -8.4652e-02,  2.5320e-01,\n",
       "         -3.7940e-01,  3.0901e-01,  7.2335e-02, -4.1282e-01, -1.7456e-02,\n",
       "         -4.1210e-01,  2.9618e-01,  1.5734e-01, -4.8750e-01,  1.8886e-02,\n",
       "         -8.3931e-02, -6.1613e-01, -4.6774e-01, -4.2139e-01,  8.3593e-01,\n",
       "          4.7391e-01, -1.4556e-01,  1.5543e-01, -1.0509e-01, -5.2149e-01,\n",
       "          5.4072e-01,  3.1979e-01, -3.6404e-01,  5.5739e-01,  5.8334e-01,\n",
       "          3.3225e-01,  2.0594e-02,  5.5425e-01, -9.2405e-02,  9.5459e-02,\n",
       "          2.2007e-01,  2.9457e-01,  1.7611e-01, -3.2029e-01, -6.2221e-02,\n",
       "         -1.7242e-01,  1.2162e-01,  1.6302e-01, -2.6112e-01,  2.9247e-01,\n",
       "          1.8715e-01,  1.8545e-01, -1.2999e-01, -2.1933e-01,  2.9410e-01,\n",
       "          1.5348e-01, -1.1808e-01, -1.6541e-01,  1.4370e-01, -2.0180e-01,\n",
       "         -3.3778e-01,  6.4413e-01, -2.1856e-01, -4.0255e-02,  9.4002e-01,\n",
       "          6.9980e-02,  1.7667e-01, -8.4181e-01]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ab5183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df2f031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.8083, -0.1043, -0.2994],\n",
       "        [ 1.7996,  1.9506,  0.1189],\n",
       "        [ 1.3044, -1.0015, -0.3298],\n",
       "        [-1.0542,  0.0592, -0.2689],\n",
       "        [ 1.3766, -1.7915,  0.8468]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae834d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0489, 0.8498, 0.0000],\n",
       "        [1.6331, 1.5277, 0.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e483ba22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d6d590c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 4.3876e-01, -1.2605e+00, -5.9349e-01,  7.5111e-01, -1.1380e+00,\n",
       "                        2.5091e+00, -1.4615e+00,  7.7578e-02],\n",
       "                      [ 3.6788e-01, -1.1163e+00, -1.7078e-02, -9.2126e-02, -4.6682e-01,\n",
       "                        7.5107e-01,  2.9649e-01, -1.7432e+00],\n",
       "                      [-2.0523e+00, -5.6545e-01, -1.3460e+00, -1.5920e-01, -2.5378e-02,\n",
       "                        6.7565e-01, -1.8494e+00, -1.1006e+00],\n",
       "                      [-8.5919e-01,  6.9389e-01,  2.4644e-02,  2.4950e-01, -1.1889e-01,\n",
       "                        3.2257e-01, -9.8427e-01, -2.9167e-01],\n",
       "                      [ 1.3556e-01, -1.5844e+00,  7.3688e-01,  4.4880e-01, -1.4792e-01,\n",
       "                        8.5940e-01, -2.2937e+00, -1.3677e+00],\n",
       "                      [ 6.3660e-01, -7.4961e-01, -1.2010e+00, -8.8958e-01,  1.6995e+00,\n",
       "                       -1.4833e+00, -6.1816e-01,  6.0311e-01],\n",
       "                      [-9.6221e-01,  1.6177e+00,  5.9987e-02,  1.0916e+00,  2.3413e-01,\n",
       "                        1.5075e-01, -8.1201e-02,  8.8334e-01],\n",
       "                      [-1.1240e+00, -2.4415e-02,  6.1361e-01, -6.7087e-02, -2.3839e-02,\n",
       "                       -8.7514e-01,  1.8263e-01,  1.2486e+00],\n",
       "                      [-1.1746e-02,  1.6568e+00,  4.6097e-01,  2.1873e+00, -8.0573e-01,\n",
       "                        4.9009e-01, -8.8614e-01,  3.6206e-01],\n",
       "                      [ 7.7368e-01, -4.3694e-01,  1.8419e+00, -4.6901e-01,  1.4127e+00,\n",
       "                       -8.3691e-01, -1.7908e-01,  3.9808e-01],\n",
       "                      [-7.2428e-01, -4.2864e-01, -2.3615e-01, -1.8269e+00,  5.2836e-01,\n",
       "                        6.3358e-01, -1.4570e+00,  1.2693e+00],\n",
       "                      [ 3.5164e-01,  1.1047e+00,  8.3678e-01,  1.4925e+00,  4.2069e-01,\n",
       "                       -1.0147e+00, -1.1109e-01,  2.3326e+00],\n",
       "                      [-1.0722e+00,  2.1932e-01, -7.6299e-01, -5.6012e-01,  6.7732e-01,\n",
       "                       -7.5914e-01,  2.6402e-01,  1.3134e+00],\n",
       "                      [-6.1593e-01, -1.0034e+00,  2.7226e-01,  6.1477e-01, -1.8050e+00,\n",
       "                       -2.0766e+00, -8.5140e-02,  4.4802e-01],\n",
       "                      [ 7.8129e-01, -6.4272e-02,  2.4000e-01, -1.7796e+00, -1.1701e+00,\n",
       "                        9.4736e-02,  1.3951e+00,  5.7158e-01],\n",
       "                      [-2.0629e-01, -9.2616e-01,  1.4394e-01, -1.6541e+00,  8.3081e-01,\n",
       "                        6.6228e-01, -1.4096e+00, -1.9096e-01],\n",
       "                      [-4.8242e-01,  1.3939e+00,  9.4835e-01, -5.0200e-01, -5.0299e-01,\n",
       "                        3.0143e-01, -4.7991e-01,  1.4814e+00],\n",
       "                      [ 2.0256e-01,  3.8876e-01,  6.8719e-01,  1.1156e+00,  8.2753e-02,\n",
       "                        6.1463e-01, -1.3338e-01, -1.7556e+00],\n",
       "                      [ 1.0919e+00,  9.0409e-02,  1.8034e+00, -2.4507e-03,  1.4171e+00,\n",
       "                       -4.6014e-01, -1.2870e+00,  8.4101e-01],\n",
       "                      [ 1.2176e-01, -9.7117e-01,  8.2587e-02,  9.8998e-01, -1.8885e-01,\n",
       "                       -3.0911e-02, -1.7946e-01,  7.7513e-01],\n",
       "                      [-8.7798e-01,  3.8494e-01,  9.5709e-01, -6.2337e-01, -2.0773e-02,\n",
       "                        1.1843e+00, -1.6153e-01,  8.1922e-03],\n",
       "                      [ 4.7679e-02,  2.0683e+00,  4.2234e-01,  3.2986e+00,  2.7320e-02,\n",
       "                       -8.4099e-02, -5.7386e-01,  2.4900e-02],\n",
       "                      [ 6.4550e-01, -2.0199e-01, -5.7637e-01, -1.4583e-02,  8.1333e-01,\n",
       "                       -1.5196e-01, -3.2095e-03,  1.6293e+00],\n",
       "                      [-1.3240e-01,  6.5229e-04, -1.0999e+00, -8.4656e-01, -1.7353e+00,\n",
       "                        6.0090e-01,  4.4152e-01, -3.6810e-02],\n",
       "                      [ 1.5384e+00,  1.5702e-01,  6.7436e-01, -1.4064e+00, -2.1802e+00,\n",
       "                       -3.1723e-01, -2.0777e+00,  1.2173e+00],\n",
       "                      [ 1.1723e+00,  1.2390e-01,  1.5605e-02,  2.8410e-01,  2.0757e+00,\n",
       "                        1.1171e+00,  1.0827e+00,  2.2223e-01],\n",
       "                      [-8.3383e-01, -7.7071e-02, -1.0016e-01,  2.2553e-01, -1.6261e+00,\n",
       "                       -6.9847e-01,  1.0477e+00,  2.3062e-01],\n",
       "                      [ 9.0775e-01,  3.7876e-01, -8.7055e-01, -9.6133e-01, -1.0570e-01,\n",
       "                       -1.5346e-02, -5.4857e-01,  1.1967e+00],\n",
       "                      [-4.2313e-01,  3.1411e-01,  1.4257e+00,  6.7293e-01, -4.4487e-01,\n",
       "                       -4.9558e-01,  2.5632e-01, -9.3777e-01],\n",
       "                      [-8.0583e-01, -1.2820e+00, -5.4438e-01,  5.3502e-01,  1.7646e-01,\n",
       "                       -9.9877e-01, -1.3486e-01, -1.2594e+00],\n",
       "                      [ 4.9627e-01,  2.6535e+00,  2.1037e-01, -1.0802e+00,  1.4918e-01,\n",
       "                        7.4664e-03, -1.1046e+00,  6.4528e-02],\n",
       "                      [ 6.8959e-01, -5.8923e-01,  9.7352e-01, -2.0159e-01, -2.2937e-01,\n",
       "                       -1.3407e+00,  6.7167e-01, -1.3470e+00],\n",
       "                      [ 5.5922e-01,  2.7461e-01, -7.9624e-01, -1.9420e+00,  2.3180e-01,\n",
       "                        1.5137e+00, -6.5941e-01, -1.0521e+00],\n",
       "                      [ 7.4330e-01, -8.1320e-01,  8.2036e-01, -8.3380e-01, -7.5408e-01,\n",
       "                        4.5427e-01,  8.8407e-01, -3.0831e-01],\n",
       "                      [ 9.9394e-01, -9.4424e-01,  4.9547e-01,  6.4181e-01,  4.3189e-01,\n",
       "                       -5.2296e-01,  1.7458e-01, -1.0980e+00],\n",
       "                      [ 1.7386e+00,  1.4023e+00,  7.5508e-02,  8.3904e-01,  1.0615e+00,\n",
       "                        4.6310e-01,  1.5164e+00,  8.1354e-01],\n",
       "                      [ 1.7517e+00, -6.0187e-01,  1.7475e-03, -4.3771e-01, -3.2674e-01,\n",
       "                       -2.4141e+00,  5.2492e-01,  3.0851e+00],\n",
       "                      [ 1.2302e+00,  6.6918e-01,  7.2376e-01, -2.0216e+00,  9.2874e-01,\n",
       "                       -2.1369e-01,  3.1623e+00, -1.5905e+00],\n",
       "                      [-4.8696e-01, -9.0642e-01,  7.6989e-01,  1.5608e+00, -1.0848e+00,\n",
       "                        4.3358e-01, -1.7336e+00, -2.0547e+00],\n",
       "                      [-6.0268e-02,  7.1734e-01,  4.8810e-02, -1.1327e+00,  1.3469e-01,\n",
       "                       -5.5735e-01, -4.0570e-01, -1.1252e+00],\n",
       "                      [ 8.3973e-02,  1.9928e+00,  1.6459e+00,  2.5075e-01,  6.5277e-01,\n",
       "                       -2.0319e-01,  1.5474e+00,  3.1961e-01],\n",
       "                      [ 2.6289e+00, -2.2885e+00,  6.5594e-01,  2.2730e-01, -1.7892e+00,\n",
       "                       -9.7216e-01,  1.3842e+00,  8.1400e-01],\n",
       "                      [-1.4678e-01, -2.0660e-01,  1.6962e+00,  5.8838e-01,  9.8641e-01,\n",
       "                       -2.4185e-01, -5.3171e-01, -1.8789e+00],\n",
       "                      [-6.3857e-02,  6.9183e-01, -2.7469e-01, -1.2586e+00,  1.0426e-01,\n",
       "                        7.9327e-01, -6.6035e-02,  1.2428e+00],\n",
       "                      [ 7.0854e-01, -1.5443e-01,  8.6262e-01, -1.1914e+00, -2.1647e-01,\n",
       "                        2.5603e-02,  2.1027e-01, -4.7496e-03],\n",
       "                      [ 1.3299e+00,  1.5263e+00,  3.9044e-01, -3.3640e-02, -6.7356e-01,\n",
       "                       -1.7735e-01, -6.2735e-01, -8.6569e-01],\n",
       "                      [-1.8895e-01,  6.8887e-02, -1.3146e-01, -1.2818e+00,  7.3896e-01,\n",
       "                        2.2331e+00, -2.1197e-01,  9.0482e-01],\n",
       "                      [ 1.9301e+00, -4.4548e-01, -3.7572e-01, -7.0468e-01,  3.3764e-01,\n",
       "                        9.6647e-01, -2.8729e-01,  5.0783e-01],\n",
       "                      [-6.0865e-01,  8.2921e-01,  1.2454e+00, -9.3227e-01, -7.7590e-01,\n",
       "                       -3.5677e-01, -2.0996e+00,  1.5785e+00],\n",
       "                      [-5.4545e-01, -2.2531e+00, -5.3523e-01, -2.0738e-01,  1.0518e-01,\n",
       "                        9.1180e-01,  4.2852e-01,  8.4660e-01],\n",
       "                      [ 4.2957e-01, -4.6609e-01,  2.1534e+00,  7.6707e-01,  2.4147e-01,\n",
       "                       -2.7300e+00,  9.0523e-01,  1.8867e-01],\n",
       "                      [-6.1720e-01, -4.6378e-02,  8.1840e-01, -6.1610e-01, -9.3505e-02,\n",
       "                        8.9553e-02, -4.6788e-01,  2.0416e+00],\n",
       "                      [ 1.4919e+00,  1.1021e-01, -3.8222e-01, -6.3132e-01,  1.2221e-01,\n",
       "                        1.6641e-03, -5.0066e-01,  3.1441e-01],\n",
       "                      [ 1.6048e-01,  3.6024e-01,  9.8107e-01,  1.6808e-01,  3.3024e-01,\n",
       "                        1.3992e-01,  9.0786e-01, -3.8455e-03],\n",
       "                      [-3.2550e-01, -3.0333e-01,  1.5468e+00, -1.1021e+00, -2.0463e+00,\n",
       "                       -3.3811e-02,  8.9783e-02,  1.7027e+00],\n",
       "                      [-1.3617e+00, -1.6390e+00,  1.2348e+00,  8.8727e-01, -3.4075e-01,\n",
       "                       -6.2912e-01,  7.4676e-01, -1.8112e-01],\n",
       "                      [ 7.5080e-01,  8.6220e-02, -1.0280e+00,  1.5456e-01, -1.5179e-01,\n",
       "                       -3.1194e-01, -7.9312e-01,  4.0794e-01],\n",
       "                      [ 9.4387e-02,  1.2417e+00, -1.2692e+00,  2.5159e+00, -1.7741e+00,\n",
       "                        2.9327e-01, -5.3164e-01,  1.8606e+00],\n",
       "                      [-3.0100e-01,  1.3330e+00,  2.9490e+00, -1.1008e+00,  7.2787e-01,\n",
       "                        1.3465e-02, -1.4959e+00, -3.9430e-01],\n",
       "                      [ 8.8590e-01, -1.9480e+00,  8.4270e-01, -1.8058e-01, -5.6089e-01,\n",
       "                       -2.1755e-01,  2.7227e-02,  8.9306e-01],\n",
       "                      [-1.1550e-01,  4.7098e-01, -1.1079e-01,  2.0873e+00,  1.2166e+00,\n",
       "                        1.1420e-01,  9.2108e-01,  1.8692e-01],\n",
       "                      [-2.7582e-01, -1.0361e+00,  8.2849e-01, -9.0026e-01, -5.6294e-01,\n",
       "                        5.1123e-01,  2.1091e+00,  6.7471e-01],\n",
       "                      [ 1.9830e-03, -8.1008e-01, -7.1814e-01,  6.7736e-01, -3.3760e-01,\n",
       "                       -7.1047e-01, -1.0853e+00,  6.5185e-01],\n",
       "                      [ 9.3357e-01, -1.4349e+00,  1.0639e+00, -1.7870e+00,  1.0324e+00,\n",
       "                        8.0196e-01, -2.8230e-01,  2.1539e+00]])),\n",
       "             ('0.bias',\n",
       "              tensor([0.7518, 0.1291, 0.4376, 0.3604, 2.0717, 0.1044, 0.9326, 0.2711])),\n",
       "             ('1.weight',\n",
       "              tensor([[ 0.5507],\n",
       "                      [-1.4703],\n",
       "                      [-1.5176],\n",
       "                      [-0.5548],\n",
       "                      [-2.2726],\n",
       "                      [ 0.4125],\n",
       "                      [-0.8661],\n",
       "                      [ 1.0152]])),\n",
       "             ('1.bias', tensor([-0.5134]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f083bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8fc0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "974c0723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20fc8148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d46b9bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ac32511",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a2e16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bad3495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1208, -0.0664,  0.0678,  ...,  0.1392,  0.1818,  0.0259],\n",
       "        [-0.0975, -0.1599,  0.0427,  ..., -0.1208, -0.0690,  0.2153],\n",
       "        [ 0.1877,  0.0040,  0.1067,  ..., -0.1955, -0.1865, -0.1623],\n",
       "        ...,\n",
       "        [ 0.0304, -0.1066, -0.1152,  ..., -0.0456,  0.0459,  0.1431],\n",
       "        [-0.1897, -0.1595, -0.1271,  ..., -0.2012, -0.0152, -0.0188],\n",
       "        [ 0.0437, -0.1934,  0.1878,  ...,  0.1919, -0.1077, -0.0295]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.hidden.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dab08158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[ 0.1208, -0.0664,  0.0678,  ...,  0.1392,  0.1818,  0.0259],\n",
       "                      [-0.0975, -0.1599,  0.0427,  ..., -0.1208, -0.0690,  0.2153],\n",
       "                      [ 0.1877,  0.0040,  0.1067,  ..., -0.1955, -0.1865, -0.1623],\n",
       "                      ...,\n",
       "                      [ 0.0304, -0.1066, -0.1152,  ..., -0.0456,  0.0459,  0.1431],\n",
       "                      [-0.1897, -0.1595, -0.1271,  ..., -0.2012, -0.0152, -0.0188],\n",
       "                      [ 0.0437, -0.1934,  0.1878,  ...,  0.1919, -0.1077, -0.0295]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([-0.1846, -0.1519, -0.1118,  0.1135, -0.0456,  0.2072,  0.1796, -0.0482,\n",
       "                      -0.0389, -0.1063,  0.0293, -0.1453, -0.0616,  0.0753, -0.1940,  0.2008,\n",
       "                       0.2004, -0.1504,  0.1493,  0.0775, -0.0213, -0.1020, -0.1384, -0.1456,\n",
       "                      -0.0165,  0.1927, -0.1766,  0.0562, -0.0115, -0.1108,  0.0278, -0.1705,\n",
       "                       0.2003,  0.1435,  0.1957, -0.0079, -0.0032, -0.2018,  0.0078,  0.0807,\n",
       "                      -0.1115, -0.0036,  0.0492,  0.0865,  0.1203, -0.1411,  0.1890,  0.0585,\n",
       "                      -0.0909,  0.1510,  0.1553, -0.0356,  0.0336, -0.0491, -0.2100,  0.1713,\n",
       "                      -0.1631, -0.0501,  0.2221, -0.1868, -0.0376,  0.2038,  0.0427,  0.2217,\n",
       "                       0.0991,  0.0678, -0.1064,  0.0412,  0.1198, -0.0805, -0.1720, -0.1228,\n",
       "                       0.0442, -0.1636,  0.0081, -0.0061, -0.1238,  0.1896, -0.1275,  0.0153,\n",
       "                       0.0836, -0.2170,  0.1657,  0.0339, -0.0440, -0.1726,  0.1457, -0.1349,\n",
       "                      -0.0496,  0.1858, -0.2077, -0.2156, -0.0878, -0.0706,  0.0011, -0.1312,\n",
       "                      -0.1407,  0.1788, -0.2103, -0.1789,  0.2094, -0.0993, -0.0830, -0.1309,\n",
       "                      -0.0949,  0.1446, -0.1753, -0.1471,  0.1043,  0.0878,  0.0203,  0.0276,\n",
       "                       0.1872,  0.1539,  0.1184, -0.0977,  0.0074,  0.1266,  0.1165,  0.1757,\n",
       "                       0.1338, -0.1867,  0.1649, -0.0389, -0.0877,  0.1698,  0.2114, -0.1113,\n",
       "                      -0.1917,  0.0270,  0.0649,  0.0757,  0.1277,  0.0120,  0.1065,  0.0532,\n",
       "                       0.1626,  0.2167, -0.1889, -0.0016,  0.1448,  0.0142, -0.0712, -0.0253,\n",
       "                      -0.0215,  0.0839, -0.1463,  0.0045,  0.1531,  0.1997, -0.0418, -0.1800,\n",
       "                      -0.1591,  0.2205,  0.1019,  0.1565,  0.0247, -0.0328,  0.0032, -0.2033,\n",
       "                      -0.1331, -0.1608, -0.1367, -0.1745,  0.0368, -0.2189, -0.0497, -0.1776,\n",
       "                       0.0744, -0.0837,  0.0819, -0.1047,  0.0130, -0.1928, -0.0193, -0.1032,\n",
       "                      -0.1446, -0.0469, -0.2100, -0.1758, -0.1214,  0.1317, -0.1589,  0.0803,\n",
       "                       0.1419,  0.1589, -0.1831, -0.0118,  0.0850, -0.0303,  0.1864,  0.0221,\n",
       "                      -0.0149, -0.0886,  0.1208,  0.1379,  0.2069, -0.1492,  0.0355, -0.1746,\n",
       "                       0.2145, -0.1153, -0.1735,  0.0090,  0.0964, -0.0396, -0.2070, -0.2076,\n",
       "                       0.0038, -0.0876,  0.0341, -0.2058,  0.1615, -0.1819, -0.2088, -0.1453,\n",
       "                       0.1361, -0.1826,  0.1392, -0.1534, -0.2168,  0.1930, -0.0118,  0.1304,\n",
       "                      -0.0514,  0.0701, -0.0028,  0.1920,  0.1286,  0.0367,  0.1608,  0.0462,\n",
       "                       0.2092, -0.2167,  0.0732, -0.0073,  0.0935, -0.0239, -0.0919,  0.2197,\n",
       "                      -0.1454, -0.1847,  0.0784,  0.1105,  0.1894,  0.0936,  0.1051,  0.1371,\n",
       "                      -0.2002,  0.0592, -0.0183,  0.1585, -0.1075, -0.0055,  0.1834, -0.0121])),\n",
       "             ('output.weight',\n",
       "              tensor([[ 1.8839e-02,  6.1684e-03, -3.1032e-02,  ...,  5.6442e-02,\n",
       "                        4.1553e-02, -2.2086e-02],\n",
       "                      [-3.3420e-02, -2.9907e-03,  3.1661e-02,  ..., -9.8927e-03,\n",
       "                       -6.2622e-04, -5.5783e-02],\n",
       "                      [-3.0710e-02,  4.1515e-02,  5.4424e-02,  ...,  6.3083e-03,\n",
       "                       -4.2660e-02, -1.1144e-02],\n",
       "                      ...,\n",
       "                      [ 4.6575e-02,  5.3970e-02,  3.0690e-02,  ...,  5.2898e-02,\n",
       "                       -5.2872e-02,  3.4339e-02],\n",
       "                      [ 2.4206e-02,  5.2342e-02,  3.5228e-02,  ...,  2.6733e-05,\n",
       "                       -5.4268e-02, -1.9174e-02],\n",
       "                      [-4.1893e-02,  4.7602e-02,  6.1616e-02,  ..., -6.2041e-02,\n",
       "                        3.8975e-02,  2.7927e-02]])),\n",
       "             ('output.bias',\n",
       "              tensor([-0.0144,  0.0026,  0.0574,  0.0257,  0.0282,  0.0027, -0.0353,  0.0221,\n",
       "                      -0.0118, -0.0393]))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f63539a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6412b94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26762551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a29c3ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modprobe: ERROR: could not insert 'nvidia': No such device\r\n",
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35a76be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cuda'), device(type='cuda', index=1))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80077c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cpu')\n",
    "torch.device('cuda')\n",
    "torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0df3093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/d2l/lib/python3.8/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 6050). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1749b642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'), [device(type='cpu')])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():  #@save\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef3cf39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "289aaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "month=list(range(1,12+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21b6092c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aa7446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "day=list(range(1,6+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ccfed55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9efcb415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today is       1.00 month 1 day\n",
      "today is       2.00 month 2 day\n",
      "today is       3.00 month 3 day\n",
      "today is       4.00 month 4 day\n",
      "today is       5.00 month 5 day\n",
      "today is       6.00 month 6 day\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(month,day):\n",
    "    print(f'today is {i:10.2f} month {j} day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56cd1d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "548e99b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to f-string expression (3279034785.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [68]\u001b[0;36m\u001b[0m\n\u001b[0;31m    f'a{i}'=123\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to f-string expression\n"
     ]
    }
   ],
   "source": [
    "f'a{i}'=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0e7b7e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, device=try_gpu())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d52e5fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0222, 0.8680, 0.2273],\n",
       "        [0.0805, 0.9940, 0.7173]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.rand(2, 3, device=try_gpu(1))\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74535e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X.cuda(1)\n",
    "print(X)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa76c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc25958",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.cuda(1) is Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fab29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(3, 1))\n",
    "net = net.to(device=try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e976cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb152030",
   "metadata": {},
   "outputs": [],
   "source": [
    "net[0].weight.data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1dfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381a262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34b7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158aa18f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
